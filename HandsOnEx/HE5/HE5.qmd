---
title: "Hands-On Exercise 5: Global and Local Measures of Spatial Autocorrelation"
author:
  - name: Matthew Ho
    url: https://www.linkedin.com/in/matthewhoyiwen/
date: 02-03-2024
description: |
  Global and Local Measures of Spatial Autocorrelation
categories:
  - Hands-On Exercise
format:
  html:
    toc: true
execute: 
  eval: true
  echo: true
  warning: false
---

## Notes
#### Tobler's First law of Geography

Everything is related to everything else but near things are more related than distant things. 

Relates to spatial dependence and spatial autocorrelation

#### Spatial Dependency

Spatial relationship of variable values over space or locations
Measured as the existence of statistical dependence in a collection of random variables, each associated with a different geographical location

#### Spatial Autocorrelation

The presence of systematic spatial variation in a variable

Can assume values 

-   At any point on a continuous surface
-   At a set of fixed states within a region
-   Across a set of areas subdividing a region (Like MPSZ Subzones)


#### Positive Spatial Autocorrelation (Higher value)

-   Clustering: Values tend to be similar in similar locations

-   Neighbors are similar: More similar than under spatial randomness

-   Compatible with diffusion but not necessarily caused by diffusion


#### Negative Spatial Autocorrelation

-   Checkerboard: Opposite of clustering 
-   Different neighbors: More dissimilar than under randomness
-   Compatible with competition but not necessarily caused by competition

#### Measures of Global Spatial Autocorrelation

-   Moran's I: How features differ from the values in the study area as a whole

  -   I > 0: Clustered, observations tend ot be similar
  -   I < 0: Dispersed, observations tend to be different
  -   I near 0: Observations are arranged randomly over space
  
-   Geary's C: Describes how features differ from their immediate neighbors

  -   C approaches 0 when clustered 
  -   C approaches 3 when different values tend to cluster
  -   High values of C corresponds with low I
  -   Inverse relationship
  
#### Spatial Randomness
-   Null Hypothesis $H_0$ 
  -   Observed spatial pattern is equally as likely as any other pattern
  -   Values at one location do not depend on neighbours
  -   Under spatial randomness, value locations may be altered without affecting the information content of the data
  
-   Doubting the assumption of Moran's I on normality and randomisation
  -   Use Monte Carlo simulation
  -   Simulate Moran's I under the assumption of no spatial pattern
  -   Assign all regions the mean value
  -   Calculate Moran's I
  -   Compare actual Moran's I to the simulations to obtain p-values
  
#### Measures of Global high/low clustering (Getis-Ord Global G)
-   Concerns the overall concentration or lack thereof in all pairs of neighbours given the definition of "neighbour" (Rook or Queen?)
-   Can only handle postiive values

#### Interpreting Getis-Ord Global G
-   p value not statistically significant
  -   Cannot reject null hypothesis
  
-   p value statistically significant and z score is positive
  -   Can reject null, spatial distribution of high values is more clustered than expected if random
-   p value is statistically significant z score is negative
  -   Can reject null, spatial distribution of low values is more clustered than expected if random
  
#### Local Spatial Autocorrelation Statistics
-   Geospatial Statistical Analysis methods to analyse the location-related tendency (Clusters or not) in the attributes of geographically referenced data

-   Can be indices from their global measures
    -   Local Moran's I
    -   Local Geary's C
    -   Getis-Ord Gi*
    
    
-   Good for 
  -   Detecting clusters or outleirs
  -   Identify hot or cold spot areas
  -   Assess the assumptions of Stationarity
  -   Identify distances beyond discernible associates (Long reaching influences?)
  
  
#### Local Indicator of Spatial Association (LISA)
-   Subset of localised geospatial statistics methods
-   Any spatial stats method satisfying:
  -   LISA for every observation indicates the extent of significant spatial clustering of similar values around that observation
  -   Sum of LISAs for all observations is proportionate to a global indicator of spatial association
  
#### Detecting Spatial Clusters and Outliers
-   Given a set of geospatial features and an analysis field, the spatial stats identify spatial clusters of features with high or low values. Also identifies spatial outliers 

-   Local Moran's I is most popular
-   Generally, the analysis calculates a local statistic value, z-score, pseudo p-value and code to represent the cluster type for every statistically signifcant feature.

-   Use z-scores abd p-values to represent statistical significance of computed index values

#### Local Moran's I
-   Outlier: significant and negative if location i is associated with relatively low values in surrounding locations
-   Cluster: significant and postive if location i is associated with relative high values in surrounding locations

-   Common alphas: 0.1, 0.05, 0.01, 0.001
  
-   Consider the quadrants when plotting Local Moran in Scatterplot
  -   LL & HH: Cluster, else outlier
  -   LH & HL: Low/High outlier among low/high neighbours
  

#### Hot and Cold Spot Areas
For a set of geospatial features in a study area, spatial stats tell us where values with high or low values cluster spatially

-   Use the Gi* (Getis-Ord Gi*)
-   Hot-spot: Significant and positive if location i is associated with relatively high values 

-   Cold-spot: Significant and negative if location i is associated with relatively low values


#### Fixed weighting schemes:
Several considerations if using fixed distances

-   All features need at least one neighbour
-   No feature should be neighbours with all others
-   Features should have about 8 neighbours each, especially if values for the inpout field are skewed
-   Might proiduce large estiamte variances with sparse data and mask subtle local variations with dense data
-   Fixed schemes may not be able to calibrate in local areas where data is too sparse to meet calibration requirements (Observations must be more than parameters)

#### Adaptive weighting schemes
Adjust themselves according to data density (Not a global thing)

-   BWs are shorter with dense data and vice versa
-   Finding NN is a common approach

#### Best Practices
-   Need at least 30 features
-   Input field must be a continuous data type. Not categorical

#### Spatial weighting method selection 
-   Polygon continuity
  -   Good if polygons are similar in size and distribution and when spatial relationships are a function of polygon proximity (shared borders increasing interaction)
  
  -   Select row standardization if available

-   Fixed-distance works well for point data or where polygon data has large variance in polygon size and you want a consistent scale of analysis

-   Inverse distance: Best with continuous data or to model processes where closer features are more likely to interact with or influence each other
  -   In this approach, every polygon is potentially a neighbor. Computationally difficult
  
  
#### Spatial weighing method selection
-   KNN is good to ensure a minimum number of neighbours
  -   Very good if values are skewed
  -   Good with varying distributions
  -   Note that spatial context of analysis changes with sparsity and density variations
  -   When fixing scale is less important than number of neighbours, KNN is good
  

#### Fixed=dsitance bandwidth values
-   Choose a distance based on known geographic extent of the spatial processes promoting clustering for the studied phenomena

-   Needs to be big enough to guarantee at least one neighbour

-   Need the following criteria
  -   At least one neighbour
  -   No feature should be neighbours with all others
  -   About 8 if data is skewed
  

#### Emerging Hotspot Analysis (EHSA)
-   Technique that falls under Exploratory Spatial Data Analysis (ESDA)
-   Combines Hotspot analysis with Getis-Ord Gi* with time-series Mann-Kendall test for monotonic trends
-   Evaluate how hot and cold spots change over time
    -   Are they becoming increasingly hotter? Cooling down? Staying same?
    

#### Mann-Kendall test for trend overview
-   Non-parametric, but should not have serial correlation
-   If normal distribution, normal regression works

-   Check rate of change over time and statiscal significance

$H_0$ : No monotonic trend

$H_1$ : A trend exists, can be postive, negative or non-null

Does not assess the magnitude of change, can find trends in as few as 4 samples, but may not find it. Recommended at least 8-10 points


#### Data requirements
Ensure that
-   Data is not collected seasonally (e.g. only in winter and summer). Needs the seasonal Kendall Test
-   No covarities, i.e. other factos influencing data other than the plotted data
-   Only one data point per time period. Use Median if more than one

#### EHSA Patterns for Hot Spot Trends (Typically based on 90% of time-step intervals)
-   No pattern
-   New hot spot
-   Consecutive hot spot
-   Intensifying hot spot
-   Persistent hot spot
-   Diminishing hot spot
-   Sporadic hot spot
-   Oscillating hot spot
-   Historical hot spot

#### EHSA Patterns for Cold Spot Trends 
-   New cold spot
-   Consecutive cold spot
-   Intensifying cold spot
-   Persistent cold spot
-   Diminishing cold spot
-   Sporadic cold spot
-   Oscillating cold spot
-   Historical cold spot

#### Spacetime cudes
A spacetime object is a spacetime cube if every location has a value for every time index (each location has a regular time series)

The basic unit of a spacetime cube is a bin
-   Unique combo of location and time index
    -   Collection at every location is a time-slice
    
    -   In every location, collection of evrey bin at each time index is a bin time-series
    
## 1.0 Setup

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, ggplot2)
```


```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

## 2.0 Global Measure of Spatial Autocorrelation

### 2.1 Contiguity Spatial Weights

```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```


### 2.2 Row standardised weights matrix

W = Row
B = Binary
C = Global standardise
S = Variance-stabilizing coding

Zero: Weights vectors of zero length are inserted for regions with no neighbours. Will create lag values of 0.
```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

### 2.3 Moran's I

```{r}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```
The result shows that it GDPPC is clustered, with a very small p-value, meaning it is very unlikely to occur by chance


```{r}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

When run with the assumption of no spatial pattern, our data's Moran's I score outranks all of them. The pseudo-p value here is 0.001, meaning the chance that our data's clustering pattern coincidentally happened to be the best is 1/1000.

```{r}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 

ggplot(data = data.frame(res = bperm$res), aes(x = res)) +
  geom_histogram(fill = "lightblue", color = "black") +
  labs(x = "Simulated Moran's I", y = "Frequency") +
  theme_minimal() +

  geom_vline(xintercept = 0, color = "red")
```


### 2.4 Geary's C
From this, we can tell that the data is skewed

```{r}
geary.test(hunan$GDPPC, listw=rswm_q)
```

The geary statistic is 0.69, which is closer to 0 than it is to 3, indicating clustering. The p value is also very small, meaning that this is unlikely to be a coincidence.

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

In case we doubt the result, we run the monte carlo test to get a pesudo p value. Similarly to the Moran's I test, our data's Geary's C outranks all of the other simulations. This indicates that the chance of our data's Geary C score outranking all of the other simulations by coincidence is 1/1000, which is very unlikely. 

```{r}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```
The simulated values seem to follow a normal distribution

```{r}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

```{r}
print(MI_corr)
```

The plot above seems to show that the correlation between pairs of spatial observations decreases with distance. As such, the measured phenomena are likely localized.

From the statistics, the Moran's I scores are mostly statistically significant.

```{r}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

```{r}
print(GC_corr)
```

## 3.0 Local Measures of Spatial Autocorrelation

### 3.1 Cluster and Outlier Analysis

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

### 3.2 LISA Cluster Map
#### Moran Scatterplots

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

#### LISA map classes
```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))

hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     

LM_I <- localMI[,1] - mean(localMI[,1])    

signif <- 0.05 
```

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      

quadrant[localMI[,5]>signif] <- 0
```

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```
From this visualisation, we can infer that the GDPPC spatial clusters identified with local moran scores are generally statistically significant in the northeastern region

## 4.0 Hot spot and cold spot area analysis

### 4.1 Deriving Centroids
```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
coords <- cbind(longitude, latitude)
```

### 4.2 Determining Cutoff Distance
```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

### 4.3 Computing fixed distance weight matrix
```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### 4.4 Computing adaptive distance weight matrix
```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

## 5.0 Computing Gi Statistics

### 5.1 Gi statisitcs using fixed distance
```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```
From this plot, we can see that there is a particularly hot spot in the north east, but also 4 particularly cold spots elsewhere that were not previously visible when using a distance weight matrix derived with a fixed bandwidth of 62KM.

#### 5.2 Adaptive Distance
```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```

From this plot, we can see a hotspot in the north east, but the cold spots are focused in a small south-western region. This visualisation is different from the fixed weighting scheme because we used an adaptive weighting scheme, which may have helped overcome the issue of unevenly sized polygons.















































































































































































































